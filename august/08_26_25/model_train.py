"""
Author: Amiri Hayes
Date: 08/26/2025
Github: https://amirihayes.github.io/sandbox/
Colab: https://colab.research.google.com/drive/1SPyget7nNAqrjbu89101CZ6Ez4GobBFz
Notes: I'm gonna use fancy comments & maybe even logging
"""

###################  imports ###################
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
import numpy as np
from tqdm import tqdm
import os

###################  config info ###################

BATCH_SIZE = 128
EPOCHS = 30
PATIENCE = 5
LR = 1e-3
MODEL_PATH = "model_weights.pth"

###################  dataset info ###################

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,),(0.5,))
])

train_dataset = datasets.EMNIST(root="./data", split="byclass", train=True, download=True, transform=transform)
test_dataset = datasets.EMNIST(root="./data", split="byclass", train=False, download=True, transform=transform)

num_classes = len(train_dataset.classes)
print("Dataset Loaded...")
print(f"Classes: {num_classes} \nTotal Train: {len(train_dataset)} \nTotal Test: {len(test_dataset)}")

val_size = int(0.1 * len(train_dataset))
train_size = len(train_dataset) - val_size
train_set, val_set = random_split(train_dataset, [train_size, val_size])

train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_set, batch_size=BATCH_SIZE)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)

label_dict = {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'A': 10,
              'B': 11, 'C': 12, 'D': 13, 'E': 14, 'F': 15, 'G': 16, 'H': 17, 'I': 18, 'J': 19, 'K': 20,
              'L': 21, 'M': 22, 'N': 23, 'O': 24, 'P': 25, 'Q': 26, 'R': 27, 'S': 28, 'T': 29, 'U': 30,
              'V': 31, 'W': 32, 'X': 33, 'Y': 34, 'Z': 35, 'a': 36, 'b': 37, 'c': 38, 'd': 39, 'e': 40,
              'f': 41, 'g': 42, 'h': 43, 'i': 44, 'j': 45, 'k': 46, 'l': 47, 'm': 48, 'n': 49, 'o': 50,
              'p': 51, 'q': 52, 'r': 53, 's': 54, 't': 55, 'u': 56, 'v': 57, 'w': 58, 'x': 59, 'y': 60, 'z': 61}
label_dict = train_dataset.class_to_idx

###################  model implementation ###################

class CNN(nn.Module):
    def __init__(self, num_classes):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, num_classes)
        self.dropout = nn.Dropout(0.3)

    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = x.view(-1, 64 * 7 * 7)
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")
model = CNN(num_classes).to(device)

###################  training_loop ###################

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LR)

best_val_loss = np.inf
patience_counter = 0

for epoch in range(EPOCHS):
    model.train()

    train_loss = 0
    val_loss = 0
    correct, total = 0, 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        train_loss += loss.item() * images.size(0)
        _, predicted = outputs.max(1)
        correct += predicted.eq(labels).sum().item()
        total += labels.size(0)
    train_loss /= total
    train_acc = 100. * correct / total

    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss= criterion(outputs, labels)
            val_loss += loss.item() * images.size(0)
            _, predicted = outputs.max(1)
            correct += predicted.eq(labels).sum().item()
            total += labels.size(0)
    val_loss /= total
    val_acc = 100. * correct / total

    print(
        f"Epoch {epoch}/{EPOCHS} | "
        f"Train Loss: {train_loss:.4f} w/ Acc: {train_acc:.2f}% | "
        f"Val Loss: {val_loss:.4f} w/ Acc: {val_acc:.2f}%"
    )

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        patience_counter = 0
        torch.save(model.state_dict(), MODEL_PATH)
        print(f"Saved current best model w/ {train_acc:.2f}% accuracy")
    else:
        patience_counter += 1
        if patience_counter >= PATIENCE:
            print(f"\nEarly stopping @ epoch {epoch}\n\n")
            break

print("Training complete. Best model saved: ", MODEL_PATH)

"""

curl -X POST http://127.0.0.1:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"input_image": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9843137264251709, -0.9686274528503418, -0.9686274528503418, -0.9686274528503418, -0.9686274528503418, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.8509804010391235, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.6941176652908325, -0.10588234663009644, 0.011764764785766602, 0.35686278343200684, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.6941176652908325, 0.10588240623474121, -0.10588234663009644, -0.843137264251709, -1.0, -1.0, -1.0, -1.0, -0.05882352590560913, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.929411768913269, 0.9372549057006836, 0.9529411792755127, 0.9686274528503418, 0.9686274528503418, 0.9686274528503418, 0.9686274528503418, 0.9529411792755127, 0.929411768913269, -0.03529411554336548, -1.0, -1.0, -1.0, -1.0, -0.3019607663154602, 0.9137254953384399, 0.9607843160629272, 0.7490196228027344, 0.7098039388656616, 0.929411768913269, 0.929411768913269, 0.7490196228027344, 0.9607843160629272, 0.9686274528503418, 0.8352941274642944, 0.7098039388656616, 0.7098039388656616, 0.6941176652908325, 0.09019613265991211, -0.6000000238418579, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.2078431248664856, 0.843137264251709, 0.6941176652908325, -0.9686274528503418, -1.0, -1.0, -1.0, -0.9921568632125854, -0.7490196228027344, -0.7098039388656616, -0.929411768913269, -0.9607843160629272, -0.7490196228027344, -0.7490196228027344, -0.9215686321258545, -0.7098039388656616, -0.7098039388656616, -0.8352941274642944, -0.9607843160629272, -0.9686274528503418, -0.9686274528503418, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.5843137502670288, 0.7490196228027344, 0.6941176652908325, -0.9686274528503418, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.929411768913269, 0.2862745523452759, 0.9450980424880981, 0.34117650985717773, -0.9843137264251709, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9921568632125854, -0.3803921341896057, 0.3803921937942505, 0.9686274528503418, 0.4745098352432251, -0.7490196228027344, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9450980424880981, -0.6313725709915161, 0.7176470756530762, 0.9686274528503418, 0.6235294342041016, -0.3803921341896057, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9764705896377563, -0.7333333492279053, -0.3490195870399475, 0.3960784673690796, 0.9137254953384399, 0.7411764860153198, 0.24705886840820312, -0.9215686321258545, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9686274528503418, -0.9686274528503418, -0.9686274528503418, -0.929411768913269, -0.34117645025253296, 0.6078431606292725, 0.8352941274642944, 0.9843137264251709, 0.9372549057006836, -0.46666663885116577, -0.8352941274642944, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9450980424880981, -0.29411762952804565, 0.6941176652908325, 0.7098039388656616, 0.7098039388656616, 0.7490196228027344, 0.9843137264251709, 0.9764705896377563, 0.9686274528503418, 0.9843137264251709, 0.9686274528503418, 0.6000000238418579, -0.2549019455909729, -0.9450980424880981, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.7490196228027344, 0.5764706134796143, 1.0, 0.9686274528503418, 0.9686274528503418, 0.9686274528503418, 0.9137254953384399, 0.11372554302215576, 0.003921627998352051, 0.35686278343200684, 0.8274509906768799, 0.9843137264251709, 0.8274509906768799, -0.29411762952804565, -0.9450980424880981, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9450980424880981, -0.3960784077644348, -0.10588234663009644, -0.6000000238418579, -0.7098039388656616, -0.7098039388656616, -0.7490196228027344, -0.9921568632125854, -1.0, -0.9764705896377563, -0.8274509906768799, 0.058823585510253906, 0.8588235378265381, 0.6941176652908325, -0.7098039388656616, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9843137264251709, -0.9686274528503418, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.2235293984413147, 0.8509804010391235, 0.6941176652908325, -0.7098039388656616, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9607843160629272, -0.6313725709915161, 0.8274509906768799, 0.9607843160629272, -0.03529411554336548, -0.9372549057006836, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9843137264251709, -0.6235294342041016, 0.5372549295425415, 0.9686274528503418, 0.6313725709915161, -0.8274509906768799, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9843137264251709, -0.7176470756530762, 0.24705886840820312, 0.843137264251709, 0.9686274528503418, 0.035294175148010254, -0.8196078538894653, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9450980424880981, -0.35686272382736206, 0.3960784673690796, 0.9372549057006836, 0.9372549057006836, 0.3803921937942505, -0.7490196228027344, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9843137264251709, -0.1450980305671692, -0.003921568393707275, -0.35686272382736206, -0.929411768913269, -0.9607843160629272, -0.7333333492279053, -0.35686272382736206, 0.011764764785766602, 0.3960784673690796, 0.9764705896377563, 0.9372549057006836, 0.3960784673690796, -0.38823527097702026, -0.929411768913269, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9843137264251709, 0.20784318447113037, 0.8274509906768799, 0.9764705896377563, 0.7490196228027344, 0.7098039388656616, 0.929411768913269, 0.9843137264251709, 0.9764705896377563, 0.8274509906768799, 0.10588240623474121, -0.38823527097702026, -0.929411768913269, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.8274509906768799, -0.2549019455909729, 0.6941176652908325, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.34117650985717773, -0.34117645025253296, -0.929411768913269, -0.9843137264251709, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9686274528503418, -0.9686274528503418, -0.9686274528503418, -0.9686274528503418, -0.9686274528503418, -0.9843137264251709, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]}'

$json = '{"input_image": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9843137264251709, -0.9686274528503418, -0.9686274528503418, -0.9686274528503418, -0.9686274528503418, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.8509804010391235, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.6941176652908325, -0.10588234663009644, 0.011764764785766602, 0.35686278343200684, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.6941176652908325, 0.10588240623474121, -0.10588234663009644, -0.843137264251709, -1.0, -1.0, -1.0, -1.0, -0.05882352590560913, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.929411768913269, 0.9372549057006836, 0.9529411792755127, 0.9686274528503418, 0.9686274528503418, 0.9686274528503418, 0.9686274528503418, 0.9529411792755127, 0.929411768913269, -0.03529411554336548, -1.0, -1.0, -1.0, -1.0, -0.3019607663154602, 0.9137254953384399, 0.9607843160629272, 0.7490196228027344, 0.7098039388656616, 0.929411768913269, 0.929411768913269, 0.7490196228027344, 0.9607843160629272, 0.9686274528503418, 0.8352941274642944, 0.7098039388656616, 0.7098039388656616, 0.6941176652908325, 0.09019613265991211, -0.6000000238418579, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.7098039388656616, -0.2078431248664856, 0.843137264251709, 0.6941176652908325, -0.9686274528503418, -1.0, -1.0, -1.0, -0.9921568632125854, -0.7490196228027344, -0.7098039388656616, -0.929411768913269, -0.9607843160629272, -0.7490196228027344, -0.7490196228027344, -0.9215686321258545, -0.7098039388656616, -0.7098039388656616, -0.8352941274642944, -0.9607843160629272, -0.9686274528503418, -0.9686274528503418, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.5843137502670288, 0.7490196228027344, 0.6941176652908325, -0.9686274528503418, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.929411768913269, 0.2862745523452759, 0.9450980424880981, 0.34117650985717773, -0.9843137264251709, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9921568632125854, -0.3803921341896057, 0.3803921937942505, 0.9686274528503418, 0.4745098352432251, -0.7490196228027344, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9450980424880981, -0.6313725709915161, 0.7176470756530762, 0.9686274528503418, 0.6235294342041016, -0.3803921341896057, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9764705896377563, -0.7333333492279053, -0.3490195870399475, 0.3960784673690796, 0.9137254953384399, 0.7411764860153198, 0.24705886840820312, -0.9215686321258545, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9686274528503418, -0.9686274528503418, -0.9686274528503418, -0.929411768913269, -0.34117645025253296, 0.6078431606292725, 0.8352941274642944, 0.9843137264251709, 0.9372549057006836, -0.46666663885116577, -0.8352941274642944, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9450980424880981, -0.29411762952804565, 0.6941176652908325, 0.7098039388656616, 0.7098039388656616, 0.7490196228027344, 0.9843137264251709, 0.9764705896377563, 0.9686274528503418, 0.9843137264251709, 0.9686274528503418, 0.6000000238418579, -0.2549019455909729, -0.9450980424880981, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.7490196228027344, 0.5764706134796143, 1.0, 0.9686274528503418, 0.9686274528503418, 0.9686274528503418, 0.9137254953384399, 0.11372554302215576, 0.003921627998352051, 0.35686278343200684, 0.8274509906768799, 0.9843137264251709, 0.8274509906768799, -0.29411762952804565, -0.9450980424880981, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9450980424880981, -0.3960784077644348, -0.10588234663009644, -0.6000000238418579, -0.7098039388656616, -0.7098039388656616, -0.7490196228027344, -0.9921568632125854, -1.0, -0.9764705896377563, -0.8274509906768799, 0.058823585510253906, 0.8588235378265381, 0.6941176652908325, -0.7098039388656616, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9843137264251709, -0.9686274528503418, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.2235293984413147, 0.8509804010391235, 0.6941176652908325, -0.7098039388656616, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9607843160629272, -0.6313725709915161, 0.8274509906768799, 0.9607843160629272, -0.03529411554336548, -0.9372549057006836, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9843137264251709, -0.6235294342041016, 0.5372549295425415, 0.9686274528503418, 0.6313725709915161, -0.8274509906768799, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9843137264251709, -0.7176470756530762, 0.24705886840820312, 0.843137264251709, 0.9686274528503418, 0.035294175148010254, -0.8196078538894653, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9450980424880981, -0.35686272382736206, 0.3960784673690796, 0.9372549057006836, 0.9372549057006836, 0.3803921937942505, -0.7490196228027344, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9843137264251709, -0.1450980305671692, -0.003921568393707275, -0.35686272382736206, -0.929411768913269, -0.9607843160629272, -0.7333333492279053, -0.35686272382736206, 0.011764764785766602, 0.3960784673690796, 0.9764705896377563, 0.9372549057006836, 0.3960784673690796, -0.38823527097702026, -0.929411768913269, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9843137264251709, 0.20784318447113037, 0.8274509906768799, 0.9764705896377563, 0.7490196228027344, 0.7098039388656616, 0.929411768913269, 0.9843137264251709, 0.9764705896377563, 0.8274509906768799, 0.10588240623474121, -0.38823527097702026, -0.929411768913269, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.8274509906768799, -0.2549019455909729, 0.6941176652908325, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.7098039388656616, 0.34117650985717773, -0.34117645025253296, -0.929411768913269, -0.9843137264251709, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9686274528503418, -0.9686274528503418, -0.9686274528503418, -0.9686274528503418, -0.9686274528503418, -0.9843137264251709, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]}'
Invoke-RestMethod -Uri http://127.0.0.1:8000/predict -Method Post -Body $json -ContentType "application/json"
  
"""